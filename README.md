# üöÄ LogBERT MVP ‚Äî Real-Time Log Anomaly Detection  

A production-ready(ish) starter for **real-time log anomaly detection** with:  

- üì° **Streaming ingestion** (file tail by default; easy hooks for journald/syslog/Kubernetes).  
- ü§ñ **Transformer-based anomaly scoring** (BERT-family backbone; pluggable with LogBERT or any HF model).  
- üîé **Token-level explanations** via attention + optional LLM explainer (Gemini).  
- ‚öñÔ∏è **Adaptive thresholding** with feedback stored in SQLite.  
- üìä **Streamlit dashboard** for live logs, anomalies, scores, and explanations.  

---

## ‚ú® Key Features
- **Live scoring** of incoming logs with `infer.LogBERTInference`.  
- **Human explanations**: `explainer.explain` converts scores & token importances into plain-English summaries (Gemini optional).  
- **Closed-loop learning**: store human feedback and auto-tune anomaly thresholds (`FeedbackStore.compute_threshold()`).  
- **Pluggable ingestion**: start with `tail -f` on a file; scale to journald/syslog, Kafka, or Kubernetes.  
- **Simple persistence**: SQLite (`feedback.db`) for feedback and thresholds.  

---

## üóÇ Project Layout
```text
‚îú‚îÄ app/
‚îÇ  ‚îú‚îÄ dashboard_streamlit.py   # Streamlit UI (live logs & anomalies)
‚îÇ  ‚îî‚îÄ replay.py                # Replays timestamped logs
‚îú‚îÄ dynamic_log_generator.py    # Fake log generator (writes to dynamic_logs.txt)
‚îú‚îÄ fetch_logs.py               # tail_file() + helpers
‚îú‚îÄ infer.py                    # LogBERTInference (tokenizer/model, scoring, attentions)
‚îú‚îÄ explainer.py                # explain(sequence, score, tokens, token_importance)
‚îú‚îÄ store_feedback.py           # SQLite storage + adaptive threshold
‚îú‚îÄ config.py                   # Central config & defaults
‚îú‚îÄ test_pipeline.py            # Smoke test for the end-to-end loop
‚îú‚îÄ requirements.txt            # Python deps
‚îî‚îÄ README.md                   # You are here
```

---

## üîß Requirements
Python 3.10+
pip / virtualenv (or Conda)
Internet (first run) to download HF model (unless pre-cached)
Optional GPU (CUDA, auto-detected) 
Python dependencies (requirements.txt)
transformers==4.41.1
torch>=2.2,<3
numpy
pandas
streamlit>=1.34
python-dotenv
tqdm 
üí° If using Gemini for LLM explanations, set GOOGLE_API_KEY in your environment. 

---

## ‚öôÔ∏è Configuration (`config.py`)

All defaults can be overridden via `.env` or environment variables:  

```python
# Model
LOGBERT_MODEL = os.getenv("LOGBERT_MODEL", "bert-base-uncased")

# Windowing
WINDOW_TYPE = os.getenv("WINDOW_TYPE", "count")
SEQUENCE_LENGTH = int(os.getenv("SEQUENCE_LENGTH", "20"))
SLIDING_STEP = int(os.getenv("SLIDING_STEP", "5"))

# Anomaly detection
ANOMALY_THRESHOLD = float(os.getenv("ANOMALY_THRESHOLD", "0.85"))

# Drain3 parser knobs
DRAIN_DEPTH = int(os.getenv("DRAIN_DEPTH", "4"))
DRAIN_SIMILARITY = float(os.getenv("DRAIN_SIMILARITY", "0.5"))

# Explainer model (Gemini)
EXPLAINER_MODEL = "gemini-1.5-flash"

# SQLite DB
DB_PATH = os.getenv("DB_PATH", "<ABSOLUTE_PATH>/feedback.db")

# Logging & modes
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO")
BATCH_MODE = os.getenv("BATCH_MODE", "false").lower() == "true"
```

## üöÄ Quickstart
1. Create virtual environment
python3 -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install -U pip
pip install -r requirements.txt

2. (Optional) Pre-download model
python -c "from huggingface_hub import snapshot_download; \
snapshot_download('bert-base-uncased', local_dir='./models/bert-base-uncased')"

export LOGBERT_MODEL=./models/bert-base-uncased
export TRANSFORMERS_OFFLINE=1
export HF_HOME=./.hf_cache

3. Configure .env (optional but recommended)
### .env
LOGBERT_MODEL=./models/bert-base-uncased
DB_PATH=/absolute/path/to/feedback.db
ANOMALY_THRESHOLD=0.85
GOOGLE_API_KEY=your_gemini_key_here   # only if using LLM explanations

4. Generate demo logs
python dynamic_log_generator.py

5. Run dashboard
streamlit run app/dashboard_streamlit.py


## üß† Inference & Explainability

infer.LogBERTInference

Loads AutoTokenizer + AutoModelForSequenceClassification.

Uses device_map="auto".

Returns: score, tokens, token_importance, text.

explainer.explain

Input: (sequence, score, tokens, token_importance).

Returns: human-readable rationale.

If GOOGLE_API_KEY set ‚Üí uses Gemini (gemini-1.5-flash); else template-based explanation.

## üóÑ Feedback & Threshold Adaptation

store_feedback.py manages feedback + thresholds:

feedback(id, timestamp, sequence_text, score, is_true_anomaly)

settings(key PRIMARY KEY, value)

Core methods:

add_feedback(ts, log_text, score, is_true_anomaly)

compute_threshold() ‚Üí optimizes Youden‚Äôs J, saves new threshold

## üì∫ Streamlit Dashboard

Live logs (color-coded)

Anomalies table + explanations

Uses fetch_logs.tail_file for ingestion

Can swap with journald, Kafka, K8s, etc.

## üîå Ingestion Options

File tail (default)

Journald/syslog (journalctl -f -u <service>)

Kubernetes (kubectl logs -f ...)

Kafka/Fluent Bit/Filebeat ‚Üí scalable ingestion

Cloud (Cloudwatch, Stackdriver, etc.) ‚Üí SDK-based

## üß™ Testing the Pipeline
###Smoke test
```python
python - <<'PY'
from infer import LogBERTInference
m = LogBERTInference()
print(m.infer(["[ERROR] timeout on db retry"]))
PY
```

### CLI scoring
```python
python test_pipeline.py
```

### Dashboard
```python
streamlit run app/dashboard_streamlit.py
```

## üß± Production Notes

‚úÖ Fine-tune LogBERT (don‚Äôt use plain BERT for prod).

üìà Serve inference via FastAPI/gRPC + Kafka/Redis.

üîç Add Prometheus metrics.

üóÑÔ∏è Use Postgres (instead of SQLite).

üîê Remove PII in logs.

üí∏ Control costs: fallback to rule-based explanations at high volume.

## üîÆ Roadmap

Fine-tuned LogBERT weights + training scripts.

Postgres storage & labeling UI.

Async/batch inference pipeline.

Alerts ‚Üí Slack / Teams / Webhooks.

## üìú License

Choose a license (MIT/Apache 2.0). Place in repo root.



